# 数据分析

## 总体分析

预训练的BERT在三轮训练中损失持续下降，短时间内就达到较高的准确率，可见预训练参数的泛化能力很好

BERT引入了特别的位置编码，可能对改善性能也有帮助

## 下一步实验

1. 不知道掩蔽策略对模型的影响如何，下一步可以把atten_mask置为None，比较效果
2. 继续提高训练的轮数(num_epochs)，看看是否可以继续提高accuracy
3. 引入percision,recall_rate，研究训练轮数对这些指标(metrics)的影响
