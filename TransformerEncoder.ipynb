{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import tools\n",
    "import pandas\n",
    "import data_process\n",
    "import MyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # 释放未被引用的显存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pandas.read_csv('./motionClassify.csv')\n",
    "vocab = data_process.gen_vocab(data)\n",
    "data_train  =  data_process.gen_dataset(data[:40000],vocab)\n",
    "data_test = data_process.gen_dataset(data[40000:],vocab)\n",
    "Batch_size = 64\n",
    "train_iter = torch.utils.data.DataLoader(data_train,Batch_size,shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(data_test,Batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout =  768, 12, 0.1#num_hidden 其实是embedding_size或者说embedding_dim\n",
    "batch_size, num_steps = 32, 10\n",
    "lr, num_epochs, device = 2e-5, 50, tools.try_gpu()\n",
    "key_size=query_size=value_size=ffn_num_input=norm_shape=num_hiddens\n",
    "ffn_num_hiddens, num_heads =  64,12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformerEncoder(nn.Module):\n",
    "    def __init__(self,vocab_size,key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = MyTransformer.TransformerEncoder(\n",
    "            vocab_size, key_size, query_size, value_size, num_hiddens,\n",
    "            norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "            num_layers, dropout)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.dense = nn.Linear(num_hiddens,2)\n",
    "    def forward(self,X):\n",
    "        enc_X = self.encoder(X)\n",
    "        return self.dense(self.dropout(enc_X[:,0,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = transformerEncoder(len(vocab),key_size,query_size,value_size,num_hiddens,\n",
    "                         norm_shape,ffn_num_input,ffn_num_hiddens,num_heads,num_layers\n",
    "                         ,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 100/625 [01:13<08:21,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch100,loss = 0.7448557615280151\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 200/625 [02:27<06:45,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch200,loss = 0.6930150985717773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 300/625 [03:41<05:10,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch300,loss = 0.7367894649505615\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 400/625 [04:55<03:35,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch400,loss = 0.6825172901153564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 500/625 [06:09<01:59,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch500,loss = 0.5411311984062195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 600/625 [07:23<00:23,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,batch600,loss = 0.5817689299583435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [07:40<00:00,  1.36it/s]\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.adam(net.parameters(),lr,weight_decay=0.01)\n",
    "\n",
    "tools.train(net,train_iter,device,optimizer,torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:36<00:00,  4.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.7240999937057495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy=tools.test(net,test_iter,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(),'./models/model2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()  # 释放未被引用的显存"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
