{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import tools\n",
    "import pandas\n",
    "import data_process\n",
    "import MyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pandas.read_csv('./motionClassify.csv')\n",
    "vocab = data_process.gen_vocab(data)\n",
    "data_train  =  data_process.gen_dataset(data[:40000],vocab)\n",
    "data_test = data_process.gen_dataset(data[40000:],vocab)\n",
    "Batch_size = 64\n",
    "train_iter = torch.utils.data.DataLoader(data_train,Batch_size,shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(data_test,Batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_hiddens, num_layers, dropout =  256, 2, 0.1#num_hidden 其实是embedding_size或者说embedding_dim\n",
    "batch_size, num_steps = 64, 10\n",
    "lr, num_epochs, device = 0.005, 300, tools.try_gpu()\n",
    "key_size=query_size=value_size=ffn_num_input=norm_shape=num_hiddens\n",
    "ffn_num_hiddens, num_heads =  64,4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformerEncoder(nn.Module):\n",
    "    def __init__(self,vocab_size,key_size, query_size, value_size, num_hiddens,\n",
    "    norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "    num_layers, dropout):\n",
    "        super().__init__()\n",
    "        self.encoder = MyTransformer.TransformerEncoder(\n",
    "            vocab_size, key_size, query_size, value_size, num_hiddens,\n",
    "            norm_shape, ffn_num_input, ffn_num_hiddens, num_heads,\n",
    "            num_layers, dropout)\n",
    "        self.dense = nn.Linear(num_hiddens,2)\n",
    "    def forward(self,X):\n",
    "        enc_X = self.encoder(X)\n",
    "        return self.dense(enc_X[:,-1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = transformerEncoder(len(vocab),key_size,query_size,value_size,num_hiddens,\n",
    "                         norm_shape,ffn_num_input,ffn_num_hiddens,num_heads,num_layers\n",
    "                         ,dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(),lr)\n",
    "tools.train(net,train_iter,device,optimizer,torch.nn.CrossEntropyLoss())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.test(net,test_iter,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
