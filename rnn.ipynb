{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import data_process\n",
    "import tools\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class rnn(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, device):\n",
    "        super(rnn, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.rnn = nn.RNN(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, 2)  # 假设是二分类任务\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # 获取词嵌入\n",
    "        out, _ = self.rnn(x)  # RNN 前向传播\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        out = self.fc(out)  # 输出层\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class OptimizedRNN(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_size, device):\n",
    "        super(OptimizedRNN, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_size, batch_first=True, bidirectional=True)  # 双向LSTM\n",
    "        self.dropout = nn.Dropout(0.5)  # Dropout正则化\n",
    "        self.fc = nn.Linear(hidden_size * 2, 2)  # 双向LSTM输出维度需要乘2\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # 获取词嵌入\n",
    "        out, _ = self.rnn(x)  # LSTM前向传播\n",
    "        out = out[:, -1, :]  # 取最后一个时间步的输出\n",
    "        out = self.dropout(out)  # 应用Dropout\n",
    "        out = self.fc(out)  # 输出层\n",
    "        out = self.softmax(out)  # 进行Softmax归一化\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers, \n",
    "                 bidirectional, dropout, pad_idx, device):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers, \n",
    "                           bidirectional=bidirectional, dropout=dropout)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "        # text = [sent len, batch size]\n",
    "        embedded = self.dropout(self.embedding(text))  # embedded = [sent len, batch size, emb dim]\n",
    "        \n",
    "        # Pack sequence\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_lengths, enforce_sorted=False)\n",
    "        \n",
    "        packed_output, (hidden, cell) = self.rnn(packed_embedded)\n",
    "        \n",
    "        # Unpack sequence\n",
    "        output, output_lengths = nn.utils.rnn.pad_packed_sequence(packed_output)\n",
    "\n",
    "        # Concatenate the final forward and backward hidden states and apply dropout\n",
    "        hidden = self.dropout(torch.cat((hidden[-2, :, :], hidden[-1, :, :]), dim=1))  # [batch size, hid dim * num directions]\n",
    "            \n",
    "        return self.fc(hidden)  # Output of shape [batch size, output dim]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "包装数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# 自定义 collate_fn\n",
    "def collate_fn(batch):\n",
    "    texts, labels = zip(*batch)\n",
    "    \n",
    "    # 文本 padding，先转换为 Tensor\n",
    "    text_lengths = torch.tensor([len(text) for text in texts])\n",
    "    \n",
    "    # 将文本进行 padding\n",
    "    padded_texts = pad_sequence([torch.tensor(text) for text in texts], padding_value=0, batch_first=True)\n",
    "    \n",
    "    # 将标签转换为 Tensor\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    # 确保 text_lengths 是 Long 类型，并且在 CPU 上\n",
    "    text_lengths = text_lengths.to(torch.long).cpu()\n",
    "\n",
    "    return padded_texts, text_lengths, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data  = pandas.read_csv('./motionClassify.csv')\n",
    "vocab = data_process.gen_vocab(data)\n",
    "data_train  =  data_process.gen_dataset(data[:40000],vocab)\n",
    "data_test = data_process.gen_dataset(data[40000:],vocab)\n",
    "Batch_size = 64\n",
    "train_iter = torch.utils.data.DataLoader(data_train, batch_size=Batch_size, shuffle=True)\n",
    "test_iter = torch.utils.data.DataLoader(data_test,Batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_pad_index(vocab):\n",
    "#     # 如果 vocab 中没有 <pad>，手动添加一个索引\n",
    "#     if '<pad>' not in vocab.token_to_idx:\n",
    "#         # 获取当前词汇表的大小作为 <pad> 的索引\n",
    "#         PAD_IDX = len(vocab.token_to_idx)\n",
    "        \n",
    "#         # 添加 <pad> 到 token_to_idx 和 idx_to_token\n",
    "#         vocab.token_to_idx['<pad>'] = PAD_IDX\n",
    "#         vocab.idx_to_token[PAD_IDX] = '<pad>'\n",
    "        \n",
    "#         # 重新生成 idx_to_token 字典，确保同步更新\n",
    "#         vocab.idx_to_token = {idx: token for token, idx in vocab.token_to_idx.items()}\n",
    "#     else:\n",
    "#         PAD_IDX = vocab.token_to_idx['<pad>']  # 如果已有 <pad>，则直接获取其索引\n",
    "    \n",
    "#     print(f'PAD index: {PAD_IDX}')\n",
    "#     print(f'Updated Vocab Size (token_to_idx): {len(vocab.token_to_idx)}')  # 打印 token_to_idx 的大小\n",
    "#     print(f'Updated Vocab Size (idx_to_token): {len(vocab.idx_to_token)}')  # 打印 idx_to_token 的大小\n",
    "#     return PAD_IDX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.05\n",
    "# PAD_IDX = get_pad_index(vocab)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "device = torch.device('cpu' if not torch.cuda.is_available() else 'cuda:0')\n",
    "#print(f\"PAD Index: {PAD_IDX}, Vocab Size: {len(vocab.token_to_idx)}\")\n",
    "\n",
    "net1 = rnn(num_embeddings=len(vocab),embedding_dim=256,hidden_size=256,device=device)\n",
    "net2 = OptimizedRNN(num_embeddings=len(vocab), embedding_dim=256, hidden_size=256, device=device)\n",
    "net3=RNN(vocab_size=len(vocab),embedding_dim=100,hidden_dim=256,output_dim=1,n_layers=2,bidirectional=True,dropout=0.5,pad_idx=vocab.pad,device=device)\n",
    "optimizer1 = torch.optim.SGD(net1.parameters(),lr)\n",
    "optimizer2 = torch.optim.SGD(net2.parameters(),lr)\n",
    "optimizer = torch.optim.Adam(net3.parameters())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 113/625 [00:01<00:07, 72.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch100,loss = 0.6793975830078125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▎      | 210/625 [00:03<00:05, 73.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch200,loss = 0.7014930248260498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 315/625 [00:04<00:04, 73.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch300,loss = 0.6898500919342041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 411/625 [00:05<00:02, 74.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch400,loss = 0.7020999193191528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 515/625 [00:07<00:01, 73.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch500,loss = 0.6945629715919495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 612/625 [00:08<00:00, 73.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch600,loss = 0.7008679509162903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:08<00:00, 72.27it/s]\n"
     ]
    }
   ],
   "source": [
    "tools.train(net1,train_iter,device,optimizer1,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:00<00:00, 178.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4992999732494354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tools.test(net1,test_iter,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率50%，接近自然概率，训练没有效果"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 104/625 [00:04<00:22, 23.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch100,loss = 0.6917610168457031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 203/625 [00:08<00:18, 22.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch200,loss = 0.6940086483955383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 302/625 [00:13<00:14, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch300,loss = 0.7016883492469788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 404/625 [00:17<00:09, 22.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch400,loss = 0.697399914264679\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 503/625 [00:21<00:05, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch500,loss = 0.6940557956695557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▋| 602/625 [00:26<00:01, 22.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch600,loss = 0.7104886770248413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:27<00:00, 22.92it/s]\n"
     ]
    }
   ],
   "source": [
    "tools.train(net2,train_iter,device,optimizer2,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 157/157 [00:02<00:00, 54.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.4992999732494354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tools.test(net2,test_iter,device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "准确率50%，没有训练效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/625 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "RNN.forward() missing 1 required positional argument: 'text_lengths'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tools\u001b[38;5;241m.\u001b[39mtrain(net3,train_iter,device,optimizer,criterion)\n",
      "File \u001b[0;32m/workspace/zzy/EmotionClassify/tools.py:12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_iter, device, optimizer, criterion)\u001b[0m\n\u001b[1;32m      9\u001b[0m y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m y_hat \u001b[38;5;241m=\u001b[39m net(X)\n\u001b[1;32m     13\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(y_hat,y)\n\u001b[1;32m     14\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/trace/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/trace/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: RNN.forward() missing 1 required positional argument: 'text_lengths'"
     ]
    }
   ],
   "source": [
    "tools.train(net3,train_iter,device,optimizer,criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools.test(net3,test_iter,device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
